## Hbase的使用调研

本文档是对HBase的调研文档，主要包括下面几个部分。第一部分主要介绍什么是HBase以及HBase的安装和基本的使用；第二部分介绍HBase的基本原理；第三部分介绍HBase详细的配置参数说明；第四部分介绍如何使用java对HBase做相关操作；第五部分对这次调研进行总结；第六部分是相关的参考文档；

### HBase简介

这部分主要介绍什么是HBase，HBase的安装和HBase的基本使用；

#### 什么是HBase

Hbase是运行在Hadoop上的NoSQL数据库，它是一个分布式的和可扩展的大数据仓库，也就是说HBase能够利用HDFS的分布式处理模式，并从Hadoop的MapReduce程序模型中获益。这意味着在一组商业硬件上存储许多具有数十亿行和上百万列的大表。除去Hadoop的优势，HBase本身就是十分强大的数据库，它能够融合key/value存储模式带来实时查询的能力，以及通过MapReduce进行离线处理或者批处理的能力。

![逻辑结构图]({{site.github.url}}/assets/hbase/逻辑结构图.png)

#### HBase的使用场景

* 存储大量的数据，上百TBs的数据；
* 需要很高的吞吐量；
* 在大规模的数据量中进行很好性能的随机访问；
* 需要进行优雅的数据扩展；
* 结构化数据和半结构化的数据存储；
* 列结构动态变化；
* 数据需要定时删除；
* 业务场景简单，没有复杂的交叉表、事务或者关联操作；

#### 基于Hadoop集群的HBase部署

本节介绍基于Hadoop集群的HBase的部署，zk部署一个单点，jdk使用的是1.7版本，hbase使用的是1.2.3，haddop使用的是2.7.3；部署结构见下图。

![部署结构]({{site.github.url}}/assets/hbase/deploy.png)

```shell
# 下载
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/core/hadoop-2.7.3/hadoop-2.7.3.tar.gz
wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.4.8/zookeeper-3.4.8.tar.gz
wget https://mirrors.tuna.tsinghua.edu.cn/apache/hbase/1.2.3/hbase-1.2.3-bin.tar.gz
```

```shell
# 安装zk
tar -zxvf zookeeper-3.4.8.tar.gz && cd zookeeper-3.4.8
cp conf/zoo_sample.cfg conf/zoo.cfg
vi conf/zoo.cfg (dataDir=../dataDir)
cd bin
nohup ./zkServer.sh start&
```

```shell
# 安装hadoop namenode datanode1
useradd hadoop
chown hadoop: hadoop
su - hadoop
# h0045170
tar -zxvf hadoop-2.7.3.tar.gz && hadoop-2.7.3 hadoop
cd namenode
scp -r hadoop h0045109:/data/scguo/hadoop/
# 配置ssh
# 一路回车
ssh-keygen -t rsa
touch ~/.ssh/authorized_keys
# 分表把对方的 ~/.ssh/id_rsa.pub 添加到自己的 ~/.ssh/authorized_keys 中
chmod 600 ~/.ssh/authorized_keys
# 配置 配置内容参见下面的说明
vi core-site.xml hdfs-site.xml yarn-site.xml mapred-site.xml slaves
# 初始化
./hdfs namenode -format
# 启动
./start-dfs.sh
./start-yarn.sh
```

```xml
<!--etc/hadoop/core-site.xml-->
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://h0045170:9000</value>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>file:/data/scguo/hadoop/tmp</value>
		<description>Abase for other temporary directories.</description>
	</property>
</configuration>
```

```xml
<!--etc/hadoop/hdfs-site.xml-->
<configuration>
	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>h0045170:50090</value>
	</property>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file:/data/scguo/hadoop/data/name</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file:/data/scguo/hadoop/data/data</value>
	</property>
</configuration>
```

```xml
<!--etc/hadoop/yarn-site.xml-->
<configuration>
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>Master</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
</configuration>
```

```xml
<!--etc/hadoop/mapred-site.xml-->
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.address</name>
		<value>h0045170:10020</value>
	</property>
	<property>
		<name>mapreduce.jobhistory.webapp.address</name>
		<value>h0045170:19888</value>
	</property>
</configuration>
```

```shell
h0045170
h0045109
```

![hadoop启动结果]({{site.github.url}}/assets/hbase/hadoop.png)

```shell
# 安装hbase
tar -zxvf hbase-1.2.3-bin.tar.gz && mv hbase-1.2.3 hbase && cd hbase
# 配置 配置内容参见下面的说明
vi conf/regionservers conf/hbase-env.sh conf/hbase-site.xml
scp hbase h0045170:/data/scguo/hbase/
cd bin && ./start-hbase.sh
```

```shell
h0045170
h0045109
```

```shell
export JAVA_HOME=/usr/server/jdk
export HADOOP_HOME=/data/scguo/hadoop/hadoop
export HBASE_OPTS="-XX:+UseConcMarkSweepGC"
export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m"
export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m"
export HBASE_MANAGES_ZK=false
```

```xml
<!--hbase-site.xml-->
<configuration>
	<property>
		<name>hbase.rootdir</name>
		<value>hdfs://h0045170:9000/hbase</value>
	</property>
	<property>
		<name>hbase.master</name>
		<value>h0045109</value>
	</property>
	<property>
		<name>hbase.cluster.distributed</name>
		<value>true</value>
	</property>
	<property>
		<name>hbase.zookeeper.property.clientPort</name>
		<value>2181</value>
	</property>
	<property>
		<name>hbase.zookeeper.quorum</name>
		<value>h0045109</value>
	</property>
	<property>
		<name>hbase.master.info.port</name>
		<value>60010</value>
	</property>
	<property>
		<name>hbase.regionserver.info.port</name>
		<value>60020</value>
	</property>
</configuration>
```

![hbase启动结果]({{site.github.url}}/assets/hbase/hbase.png)

#### HBase shell 使用

```shell
# 创建表
hbase(main):004:0> create 'users','userid','address','info'
0 row(s) in 2.7770 seconds

=> Hbase::Table - users

# 查看表
hbase(main):006:0> list
TABLE
users
users_tmp
2 row(s) in 0.0290 seconds

=> ["users", "users_tmp"]

# 查看表详情
hbase(main):007:0> describe 'users'
Table users is ENABLED
users
COLUMN FAMILIES DESCRIPTION
{NAME => 'address', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true
'}
{NAME => 'info', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'}
{NAME => 'userid', DATA_BLOCK_ENCODING => 'NONE', BLOOMFILTER => 'ROW', REPLICATION_SCOPE => '0', VERSIONS => '1', COMPRESSION => 'NONE', MIN_VERSIONS => '0', TTL => 'FOREVER', KEEP_DELETED_CELLS => 'FALSE', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACHE => 'true'
}
3 row(s) in 0.5150 seconds

# 删除表
hbase(main):009:0> drop 'users_tmp'
0 row(s) in 1.4640 seconds

hbase(main):010:0> list
TABLE
users
1 row(s) in 0.0280 seconds

=> ["users"]

# 插入数据 查看数据
hbase(main):011:0> put 'users','xiaoming','info:age','24';
hbase(main):012:0* put 'users','xiaoming','info:class','software';
hbase(main):014:0> get 'users','xiaoming'
COLUMN                                                                CELL
 info:age                                                             timestamp=1474696855488, value=24
 info:class                                                           timestamp=1474696855554, value=software
2 row(s) in 0.1040 seconds
hbase(main):015:0> get 'users','xiaoming','info'
COLUMN                                                                CELL
 info:age                                                             timestamp=1474696855488, value=24
 info:class                                                           timestamp=1474696855554, value=software
2 row(s) in 0.0440 seconds
hbase(main):016:0> get 'users','xiaoming','info:class'
COLUMN                                                                CELL
 info:class                                                           timestamp=1474696855554, value=software
1 row(s) in 0.0440 seconds
hbase(main):003:0> get 'users','xiaoming',{COLUMN=>'info:age',VERSIONS=>1}
COLUMN                                                                CELL
 info:age                                                             timestamp=1474696942016, value=25
1 row(s) in 0.4330 seconds

hbase(main):004:0> get 'users','xiaoming',{COLUMN=>'info:age',TIMESTAMP=>1474696855488}
COLUMN                                                                CELL
 info:age                                                             timestamp=1474696855488, value=24
1 row(s) in 0.0530 seconds

# 删除
hbase(main):005:0> delete 'users','xiaoming','info:class'
0 row(s) in 0.1770 seconds

hbase(main):006:0> get 'users','xiaoming'
COLUMN                                                                CELL
 info:age                                                             timestamp=1474696942016, value=25
1 row(s) in 0.0640 seconds

hbase(main):007:0> deleteall 'users','xiaoming'
0 row(s) in 0.0430 seconds

hbase(main):008:0> get 'users','xiaoming'
COLUMN                                                                CELL
0 row(s) in 0.0490 seconds

# 遍历表
hbase(main):021:0> scan 'users'
ROW                                                                   COLUMN+CELL
 zhangyifei                                                           column=address:city, timestamp=1474697282601, value=jieyang
 zhangyifei                                                           column=address:contry, timestamp=1474697282570, value=china
 zhangyifei                                                           column=address:province, timestamp=1474697282587, value=guangdong
 zhangyifei                                                           column=info:birthday, timestamp=1474697282478, value=1987-4-17
 zhangyifei                                                           column=info:company, timestamp=1474697282555, value=alibaba
 zhangyifei                                                           column=info:favorite, timestamp=1474697282534, value=movie
1 row(s) in 0.0990 seconds

# 统计、清空表
hbase(main):024:0> count 'users'
1 row(s) in 0.0530 seconds

=> 1
hbase(main):025:0> truncate
truncate            truncate_preserve
hbase(main):025:0> truncate 'users'
Truncating 'users' table (it may take a while):
 - Disabling table...
 - Truncating table...
0 row(s) in 6.4870 seconds

hbase(main):026:0> list
TABLE
users
1 row(s) in 0.0240 seconds

=> ["users"]
```

### HBase原理与基本特性

#### HBase逻辑结构

在介绍HBase相关原理前先看下HBase的逻辑结构；

![逻辑结构图]({{site.github.url}}/assets/hbase/逻辑结构图.png)

* **Client：**
  使用HBase RPC机制与HMaster和HRegionServer进行通信；
  Client与HMaster进行通信进行管理类操作；
  Client与HRegionServer进行数据读写类操作；

* **Zookeeper：**
  Zookeeper Quorum存储-ROOT-表地址、HMaster地址；
  HRegionServer把自己以Ephedral方式注册到Zookeeper中，HMaster随时感知各个HRegionServer的健康；
  Zookeeper避免HMaster单点问题；

* **HMaster：**
  HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master在运行。
  主要负责Table和Region的管理工作：

  1. 管理用户对表的增删改查操作；
  2. 管理HRegionServer的负载均衡，调整Region分布；
  3. Region Split后，负责新Region的分布；
  4. 在HRegionServer停机后，负责失效HRegionServer上Region迁移；

* **HRegionServer：**
  HBase中最核心的模块，主要负责响应用户I/O请求，向HDFS文件系统中读写数据；![HRegion]({{site.github.url}}/assets/hbase/HRegionServer.jpg)

  HRegionServer管理一些列HRegion对象；
  每个HRegion对应Table中一个Region，HRegion由多个HStore组成；
  每个HStore对应Table中一个Column Family的存储；
  Column Family就是一个集中的存储单元，故将具有相同IO特性的Column放在一个Column Family会更高效


* **HStore：**
  HBase存储的核心。由MemStore和StoreFile组成。
  MemStore是Sorted Memory Buffer。用户写入数据的流程：

  ![]({{site.github.url}}/assets/hbase/HStore.gif)

  Client写入 -> 存入MemStore，一直到MemStore满 -> Flush成一个StoreFile，直至增长到一定阈值 -> 出发Compact合并操作 -> 多个StoreFile合并成一个StoreFile，同时进行版本合并和数据删除 -> 当StoreFiles Compact后，逐步形成越来越大的StoreFile -> 单个StoreFile大小超过一定阈值后，触发Split操作，把当前Region Split成2个Region，Region会下线，新Split出的2个孩子Region会被HMaster分配到相应的HRegionServer 上，使得原先1个Region的压力得以分流到2个Region上
  由此过程可知，HBase只是增加数据，有所得更新和删除操作，都是在Compact阶段做的，所以，用户写操作只需要进入到内存即可立即返回，从而保证I/O高性能。

* **HLog**
  引入HLog原因：
  在分布式系统环境中，无法避免系统出错或者宕机，一旦HRegionServer以外退出，MemStore中的内存数据就会丢失，引入HLog就是防止这种情况。
  工作机制：
  每 个HRegionServer中都会有一个HLog对象，HLog是一个实现Write Ahead Log的类，每次用户操作写入Memstore的同时，也会写一份数据到HLog文件，HLog文件定期会滚动出新，并删除旧的文件(已持久化到 StoreFile中的数据)。当HRegionServer意外终止后，HMaster会通过Zookeeper感知，HMaster首先处理遗留的 HLog文件，将不同region的log数据拆分，分别放到相应region目录下，然后再将失效的region重新分配，领取到这些region的 HRegionServer在Load Region的过程中，会发现有历史HLog需要处理，因此会Replay HLog中的数据到MemStore中，然后flush到StoreFiles，完成数据恢复。

* **HBase存储格式**
  HBase中的所有数据文件都存储在Hadoop HDFS文件系统上，格式主要有两种：

  1. HFile HBase中KeyValue数据的存储格式，HFile是Hadoop的二进制格式文件，实际上StoreFile就是对HFile做了轻量级包装，即StoreFile底层就是HFile；
  2. HLog File，HBase中WAL（Write Ahead Log） 的存储格式，物理上是Hadoop的Sequence File；

* **HFile**

  ![HFile]({{site.github.url}}/assets/hbase/Hfile.jpg)

  HFile文件不定长，长度固定的块只有两个：Trailer和FileInfo，Trailer中指针指向其他数据块的起始点File Info中记录了文件的一些Meta信息，例如：AVG_KEY_LEN, AVG_VALUE_LEN, LAST_KEY, COMPARATOR, MAX_SEQ_ID_KEY等。

  Data Index和Meta Index块记录了每个Data块和Meta块的起始点，Data Block是HBase I/O的基本单元，为了提高效率，HRegionServer中有基于LRU的Block Cache机制。每个Data块的大小可以在创建一个Table的时候通过参数指定，大号的Block有利于顺序Scan，小号Block利于随机查询。每个Data块除了开头的Magic以外就是一个个KeyValue对拼接而成, Magic内容就是一些随机数字，目的是防止数据损坏。HFile里面的每个KeyValue对就是一个简单的byte数组。这个byte数组里面包含了很多项，并且有固定的结构。

  ![]({{site.github.url}}/assets/hbase/HFile2.jpg)

  KeyLength和ValueLength：两个固定的长度，分别代表Key和Value的长度;
  Key部分：Row Length是固定长度的数值，表示RowKey的长度，Row 就是RowKey，Column Family Length是固定长度的数值，表示Family的长度接着就是Column Family，再接着是Qualifier，然后是两个固定长度的数值，表示Time Stamp和Key Type（Put/Delete）；
  Value部分没有这么复杂的结构，就是纯粹的二进制数据；

* **HLog File**

  ![]({{site.github.url}}/assets/hbase/HLog.jpg)

  HLog文件就是一个普通的Hadoop Sequence File，Sequence File 的Key是HLogKey对象，HLogKey中记录了写入数据的归属信息，除了table和region名字外，同时还包括 sequence number和timestamp，timestamp是“写入时间”，sequence number的起始值为0，或者是最近一次存入文件系统中sequence number。HLog Sequece File的Value是HBase的KeyValue对象，即对应HFile中的KeyValue。


####HBase表说明

HBase最基本的单位是列。一列或者多列形成行数据，并由唯一的rowkey确定；HBase的主要数据结构包括:表、行、列和单元格；其中列是可动态增加的；

![table]({{site.github.url}}/assets/hbase/table.png)

* **RowKey**

  RowKey是用来检索HBase数据记录的主要字段，类似于其他数据库中的PrimaryKey一样，是访问HBase数据库的关键；目前访问HBase数据库中的行记录只有三种方式：

  * 通过单个RowKey进行访问；
  * 通过RowKey的范围进行scan；
  * 全表扫描(不推荐)；

  HBase中的数据存储是按照行键的字典序来进行。行键是唯一指定的，只出现一次的，一般来说HBase表只支持对rowkey的单一索引，只能过rowkey来定位相关的记录，但是有扩展版的HBase支持了辅助索引的功能；

* 列族

  一行是由若干列组成的，若干列又构成一个列族，一个列族的所有列都存储在同一个底层的存储文件里，这个存储文件叫做HFile。

  列族需要在表创建的时候就定义好，目前HBase对于多列族的支持不是特别好，一般列族的数量只限于几十，实际情况可能还小的多。列族名必须由可打印字符组成。

  hbase表中的每个列，都归属与某个列族。列族是表的schema的一部分(而列不是)，必须在使用表之前定义。列名都以列族作为前缀。例如courses:history，courses:math都属于courses 这个列族。

  访问控制、磁盘和内存的使用统计都是在列族层面进行的。实际应用中，列族上的控制权限能帮助我们管理不同类型的应用：我们允许一些应用可以添加新的基本数据、一些应用可以读取基本数据并创建继承的列族、一些应用则只允许浏览数据（甚至可能因为隐私的原因不能浏览所有数据）。

* 时间戳

  HBase表中通过rowkey和列名确定的一个存储单元成为Cell单元格，每个Cell都可以保存同一字段数据的多个版本，版本通过时间戳来索引。时间戳可以在HBase写入时由客户端显式赋值，也可以由服务端默认赋值。每个Cell中，不同版本的数据按照时间倒序排序，保证最新的数据排在前面。

  为了避免数据存在过多的版本造成的管理（包括存储和索引）负担，HBase提供了两种数据版本回收方式：一种是保存数据的最后N个版本，第二种是保存最近一段时间内的版本（比如最近七天）。回收方式可以针对每个列族进行设置。

* Cell单元格

  Cell单元格是由{rowkey，column(=family+label)，timestamp}唯一确定的单元，单元格中的内容全部是字节码形式存储的。

  HBase中数据存储都是以key-value格式存储的，但是是多层的key-value关系；

  ```json
  {
  	UID1: {
  		bf：{
  			102:{
  				1329088321289:108viafly
  			}
  			111:{
  				1329088321289: 46000234573814
  			}
  			118:{
  				1329088321289: weather
  				1329088320110: telephone
  			}
  		}
  		af：{
  			404:{
  				1329088321289: 安徽
  			}
  			303:{
  				1329088321289: weather
  			}
  			319:{
  				1329088321289: 查询天气
  			}
  		}
  	}
  }
  ```

#### Filter的使用

HBase中两种主要的读取方式是scan和get，他们都是通过rowkey进行数据访问，在此基础上可以添加更多的限制条件来减少查询中传输的数据量。get和scan函数都是支持过滤器的，过滤器基本的接口叫Filter，HBase已经有一些现成的Filter类来满足相关的过滤需求，用户还可以通过集成Filter类来定制自己的限制条件；

用户定义一个所需要的过滤器实例，然后将定义好的过滤器实例传递给Get或者Scan实例；

### HBase的配置说明

| 配置项                                      | 说明                                       | 默认值                                  |
| ---------------------------------------- | ---------------------------------------- | ------------------------------------ |
| hbase.rootdir                            | regionserver持久化目录                        | file:///tmp/hbase-${user.name}/hbase |
| hbase.master.port                        | HBase的Master的端口                          | 60000                                |
| hbase.cluster.distributed                | HBase的运行模式                               | false                                |
| hbase.tmp.dir                            | 本地的临时文件夹                                 | ${java.io.tmpdir}/hbase-${user.name} |
| hbase.local.dir                          | 作为本地存储                                   | ${hbase.tmp.dir}/local/              |
| hbase.master.info.port                   | HBase Master web 界面                      | 60010                                |
| hbase.master.info.bindAddress            | 界面绑定的地址                                  | 0.0.0.0                              |
| hbase.client.write.buffer                | 客户端写缓存正相关内存                              | 2097152                              |
| hbase.regionserver.port                  | RegionServer绑定的端口                        | 60020j                               |
| hbase.regionserver.info.port             | RegionServer界面端口                         | 60030                                |
| hbase.regionserver.info.port.auto        | RegionServer界面自动                         | false                                |
| hbase.regionserver.info.bindAddress      | RegionServer绑定的ip地址                      | 0.0.0.0                              |
| hbase.regionserver.class                 | RegionServer 使用的接口                       |                                      |
| hbase.client.pause                       | 客户端在重试等待时间                               | 1000                                 |
| hbase.client.retries.number              | 最大重试次数                                   | 10                                   |
| hbase.bulkload.retries.number            | 原子批加载尝试的迭代最大次数                           | 0永不放弃                                |
| hbase.client.scanner.caching             | 客户端next不在是重新获取                           | 100                                  |
| hbase.client.keyvalue.maxsize            | 一个KV实例的最大size                            | 10485760                             |
| hbase.regionserver.lease.period          | 超时阀值                                     | 60000                                |
| hbase.regionserver.handler.count         | 受理的RPC Server实例数量                        | 10                                   |
| hbase.regionserver.msginterval           | 发消息给 Master 时间间隔                         | 3000                                 |
| hbase.regionserver.optionallogflushinterval | 将Hlog同步到HDFS的间隔                          | 1000                                 |
| hbase.regionserver.regionSplitLimit      | region的数量到了这个值后就不会在分裂了                   | 2147483647                           |
| hbase.regionserver.logroll.period        | 提交commit log的间隔                          | 3600000                              |
| hbase.regionserver.hlog.reader.impl      | HLog file reader 的实现                     | SequenceFileLogReader                |
| hbase.regionserver.hlog.writer.impl      | HLog file writer 的实现                     | SequenceFileLogWriter                |
| hbase.regionserver.nbreservationblocks   | 储备的内存block的数                             | 4                                    |
| hbase.balancer.period                    | Master执行region balancer的间隔               | 300000                               |
| hbase.regions.slop                       | 重新均衡的阈值                                  | 0.2                                  |
| hbase.master.logcleaner.ttl              | Hlog存在于.oldlogdir 文件夹的最长时间               | 600000                               |
| hbase.master.logcleaner.plugins          | 可定制                                      |                                      |
| hbase.regionserver.global.memstore.upperLimit | 单个region server的全部memtores的最大值           | 0.4                                  |
| hbase.regionserver.global.memstore.lowerLimit | 强制执行flush操作的时候，当低于这个值的时候，flush会停止        | 0.35                                 |
| hbase.server.thread.wakefrequency        | service工作的sleep间隔，单位毫秒                   | 10000                                |
| hbase.server.versionfile.writeattempts   | 退出前尝试写版本文件的次数                            | 3                                    |
| hbase.hregion.memstore.flush.size        | 当memstore的大小超过这个值的时候，会flush到磁盘           | 134217728                            |
| hbase.hregion.preclose.flush.size        | 当memstore的大小超过这个值的时候，会触发close            | 5242880                              |
| hbase.hregion.memstore.mslab.enabled     | 启用memStore分配本地缓冲区，减少GC                   | true                                 |
| hbase.hregion.max.filesize               | 最大HStoreFile大小                           | 10737418240                          |
| hbase.hstore.compactionThreshold         | HStoreFiles合并阈值                          | 3                                    |
| hbase.hstore.blockingStoreFiles          | 合并阻塞的的file阈值                             | 7                                    |
| hbase.hstore.blockingWaitTime            | 限制合并的阻塞时间                                | 90000                                |
| hbase.hstore.compaction.max              | 每个“小”合并的HStoreFiles最大数量                  | 16                                   |
| hbase.hregion.majorcompaction            | 一个Region中的所有HStoreFile的major compactions的时间间隔 | 86400000                             |
| hbase.storescanner.parallel.seek.enable  | 允许 StoreFileScanner 并行搜索 StoreScanner    | false                                |
| hbase.storescanner.parallel.seek.threads | 并行搜索特性打开后，默认线程池大小                        | 10                                   |

### HBase Java简单测试

这里对hbase驱动里面的put，scan，get进行了测试；

```java
package com.iflytek.ossp.hbase;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.HColumnDescriptor;
import org.apache.hadoop.hbase.HTableDescriptor;
import org.apache.hadoop.hbase.client.*;
import org.apache.hadoop.hbase.util.Bytes;

import java.util.ArrayList;
import java.util.List;
import java.util.function.Consumer;

/**
 * HBaseDemo程序
 * Created by scguo on 16/9/29.
 */
public class HBaseDemo {
    //表名
    private static final String tableName = "users";
    //HBase 连接相关
    private static Configuration configuration = null;
    private static HBaseAdmin admin = null;
    private static HTable hTable = null;

    /**
     * 执行主方法
     * 主要过程
     * <p>创建一个表</p>
     * <p>插入两条数据</p>
     * <p>scan这个表</p>
     * <p>get一条数据</p>
     * <p>删除这个表</p>
     *
     * @param args
     */
    public static void main(String[] args) throws Exception {
        configuration = new Configuration();
        configuration.set("hbase.zookeeper.quorum", "192.168.45.109");
        admin = new HBaseAdmin(configuration);
        hTable = new HTable(configuration, tableName);
        createTable();
        put();
        scan();
        get();
        dropTable();
    }

    /**
     * 创建一个表users,两个列族,info,address
     */
    public static void createTable() throws Exception {

        HTableDescriptor table = new HTableDescriptor(tableName);
        table.addFamily(new HColumnDescriptor("info"));
        table.addFamily(new HColumnDescriptor("address"));
        if (admin.tableExists(tableName)) {
            System.out.println("table exist.");
            admin.deleteTable(tableName);
            admin.createTable(table);
        } else {
            admin.createTable(table);
        }
    }

    /**
     * insert values to table 'users'
     *
     * @throws Exception
     */
    public static void put() throws Exception {
        List<Put> puts = new ArrayList<Put>();
        puts.add(new Put("bbb".getBytes()));
        puts.get(0).add("info".getBytes(), "age".getBytes(), "27".getBytes());
        puts.add(new Put("bbb".getBytes()));
        puts.get(1).add("info".getBytes(), "company".getBytes(), "iflytek".getBytes());
        puts.add(new Put("bbb".getBytes()));
        puts.get(2).add("info".getBytes(), "birthday".getBytes(), "1989-06-17".getBytes());
        puts.add(new Put("bbb".getBytes()));
        puts.get(3).add("address".getBytes(), "city".getBytes(), "合肥".getBytes());
        puts.add(new Put("bbb".getBytes()));
        puts.get(4).add("address".getBytes(), "province".getBytes(), "安徽".getBytes());

        puts.add(new Put("aaa".getBytes()));
        puts.get(5).add("info".getBytes(), "age".getBytes(), "27".getBytes());
        puts.add(new Put("aaa".getBytes()));
        puts.get(6).add("info".getBytes(), "company".getBytes(), "iflytek".getBytes());
        puts.add(new Put("aaa".getBytes()));
        puts.get(7).add("info".getBytes(), "birthday".getBytes(), "1989-06-17".getBytes());
        puts.add(new Put("aaa".getBytes()));
        puts.get(8).add("address".getBytes(), "city".getBytes(), "合肥".getBytes());
        puts.add(new Put("aaa".getBytes()));
        puts.get(9).add("address".getBytes(), "province".getBytes(), "安徽".getBytes());
        hTable.put(puts);
    }

    /**
     * 全表扫描Hbase
     */
    public static void scan() throws Exception {
        System.out.println("<-------------------------------------------------------------------------->");
        Scan scan = new Scan();
        ResultScanner resultScanner = hTable.getScanner(scan);
        resultScanner.forEach(new Consumer<Result>() {
            @Override
            public void accept(Result result) {
                printResult(result);
            }
        });
        System.out.println("<-------------------------------------------------------------------------->");
    }

    /**
     * 获取数据
     *
     * @throws Exception
     */
    public static void get() throws Exception {
        System.out.println("<-------------------------------------------------------------------------->");
        Get get = new Get("aaa".getBytes());
        Result result = hTable.get(get);
        printResult(result);
        System.out.println("<-------------------------------------------------------------------------->");
    }

    /**
     * 打印cell内容
     *
     * @param result
     */
    private static void printResult(Result result) {
        for (Cell cell : result.listCells()) {
            StringBuilder sb = new StringBuilder();
            sb.append("row: ").append(Bytes.toString(cell.getRow())).append(" ");
            sb.append("family: ").append(Bytes.toString(cell.getFamily())).append(" ");
            sb.append("qualifierArray: ").append(Bytes.toString(cell.getQualifier())).append(" ");
            sb.append("value: ").append(Bytes.toString(cell.getValue())).append(" ");
            sb.append("timestamp: ").append(cell.getTimestamp()).append(" ");
            System.out.println(sb.toString());
        }
    }

    /**
     * 删除这个表
     */
    public static void dropTable() throws Exception {
        admin.disableTable(tableName);
        admin.deleteTable(tableName);
    }
}
```

### 总结

HBase使用文件存储，优势是可以存储很大量的数据，单数据的访问速度上相比较内存数据库无优势。

HBase的cell支持时间戳的过期，但是过期只能按照历史版本或时间维度，而且是全局配置。

​	HBase数据中存储了时间戳信息，可以依赖时间戳判断时间是否过期；

HBase官方驱动为java版本，其他语言使用需要依赖第三方库或者自己封装。

HBase在高并发下与codis获取数据的性能对比需要进一步调研。

使用HBase可以和UBA的技术选型一致。

### 参考文档

[Hadoop集群搭建](http://www.powerxing.com/install-hadoop-cluster/)

[HBase基本操作](http://blog.csdn.net/zwx19921215/article/details/41820199)

[HBase结构说明](http://www.cnblogs.com/JemBai/archive/2012/07/21/2602432.html)
